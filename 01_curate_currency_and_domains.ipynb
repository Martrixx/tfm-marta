{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecf03bf2",
   "metadata": {},
   "source": [
    "# 01 — Curate currency & domains (staging → curated)\n",
    "\n",
    "Este cuaderno carga datos desde *staging* (Construction y AnyButConstruction),\n",
    "aplica conversión de divisa a USD con una tabla de tipos de cambio,\n",
    "homologa campos y ejecuta validaciones de integridad. Deja como salida\n",
    "tablas **curadas** en el *database* de destino.\n",
    "\n",
    "**Entradas esperadas (tablas o vistas de Spark / SQL):**\n",
    "- `stg_sap.bid_construction_database`\n",
    "- `stg_sap.bid_project_database` (AnyButConstruction)\n",
    "- `ref.exchange_rates_atlantica_2024_mod`\n",
    "\n",
    "**Salidas (tablas Spark / SQL):**\n",
    "- `cur.bid_construction_curated` (preparada y en USD)\n",
    "- `cur.bid_anybutconstruction_curated` (preparada y en USD)\n",
    "- `qa.curate_integrity_issues` (hallazgos de calidad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f995ae1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Parameters \n",
    "CATALOG = \"\"       \n",
    "DB_STAGING = \"stg_sap\"\n",
    "DB_REF = \"ref\"\n",
    "DB_CUR = \"cur\"\n",
    "DB_QA = \"qa\"\n",
    "\n",
    "TABLE_CONSTRUCTION = f\"{DB_STAGING}.bid_construction_database\"\n",
    "TABLE_ANYBUT = f\"{DB_STAGING}.bid_project_database\"\n",
    "TABLE_EXCH = f\"{DB_REF}.exchange_rates_atlantica_2024_mod\"\n",
    "\n",
    "OUT_CONSTRUCTION = f\"{DB_CUR}.bid_construction_curated\"\n",
    "OUT_ANYBUT = f\"{DB_CUR}.bid_anybutconstruction_curated\"\n",
    "OUT_QA = f\"{DB_QA}.curate_integrity_issues\"\n",
    "\n",
    "\n",
    "def qual(tbl):\n",
    "    return f\"{CATALOG}.{tbl}\" if CATALOG else tbl\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436a6139",
   "metadata": {},
   "source": [
    "## 1) Cargar tablas de *staging* y tipos de cambio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68e6b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_construction = spark.table(qual(TABLE_CONSTRUCTION))\n",
    "df_anybut = spark.table(qual(TABLE_ANYBUT))\n",
    "df_exch = spark.table(qual(TABLE_EXCH))\n",
    "\n",
    "# Normalizamos nombres esperados mínimos para el cálculo posterior\n",
    "\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "required_cols_construction = [\n",
    "    \"Project ID\",\"Project phase\",\"Bid Date\",\"Bid Number\",\"Supplier Name\",\n",
    "    \"Material Category\",\"Currency\",\"Price\",\"Purchase Order\",\"RtB Budget\"\n",
    "]\n",
    "required_cols_anybut = [\n",
    "    \"PRQ Code\",\"Bid Date\",\"Bid Number\",\"Supplier Name\",\n",
    "    \"Material Category\",\"Currency\",\"Price\",\"PO (Y/N)\",\"Round Number\",\"Winner\"\n",
    "]\n",
    "\n",
    "missing_c = [c for c in required_cols_construction if c not in df_construction.columns]\n",
    "missing_a = [c for c in required_cols_anybut if c not in df_anybut.columns]\n",
    "if missing_c or missing_a:\n",
    "    raise ValueError(f\"Faltan columnas: construction={missing_c}, anybut={missing_a}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43ed101",
   "metadata": {},
   "source": [
    "## 2) Diccionario de tipos de cambio → USD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bca888b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pyspark.sql.functions import collect_list, struct\n",
    "\n",
    "# Se espera df_exch con columnas: Currency, AvgRate\n",
    "if not set([\"Currency\",\"AvgRate\"]).issubset(set(df_exch.columns)):\n",
    "    raise ValueError(\"La tabla de tipos de cambio debe tener columnas: Currency, AvgRate\")\n",
    "\n",
    "# Convertimos a un pequeño diccionario en el driver\n",
    "pairs = df_exch.select(\"Currency\",\"AvgRate\").collect()\n",
    "exch_dict = {r[\"Currency\"]: float(r[\"AvgRate\"]) for r in pairs}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774b5d83",
   "metadata": {},
   "source": [
    "## 3) Conversión a USD y estandarización de dominios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7df59c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pyspark.sql.functions import udf, lit\n",
    "from pyspark.sql.types import DoubleType, StringType\n",
    "\n",
    "@udf(DoubleType())\n",
    "def to_usd(price, currency):\n",
    "    if currency is None or price is None:\n",
    "        return None\n",
    "    rate = exch_dict.get(currency)\n",
    "    return float(price)*float(rate) if rate is not None else None\n",
    "\n",
    "@udf(StringType())\n",
    "def usd_flag(currency):\n",
    "    return \"OK\" if currency in exch_dict else \"MISSING_RATE\"\n",
    "\n",
    "df_construction_cur = (\n",
    "    df_construction\n",
    "    .withColumn(\"Price_USD\", to_usd(col(\"Price\"), col(\"Currency\")))\n",
    "    .withColumn(\"USD_Rate_Status\", usd_flag(col(\"Currency\")))\n",
    ")\n",
    "\n",
    "df_anybut_cur = (\n",
    "    df_anybut\n",
    "    .withColumn(\"Price_USD\", to_usd(col(\"Price\"), col(\"Currency\")))\n",
    "    .withColumn(\"USD_Rate_Status\", usd_flag(col(\"Currency\")))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc45b22d",
   "metadata": {},
   "source": [
    "## 4) Validaciones de integridad (calidad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4c092e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "issues = []\n",
    "\n",
    "# 4.1 Si hay 'After' debe existir 'Before' (por Project ID)\n",
    "phases = df_construction_cur.select(\"Project ID\",\"Project phase\").dropDuplicates()\n",
    "proj_phase = phases.groupBy(\"Project ID\").agg(\n",
    "    F.collect_set(\"Project phase\").alias(\"phases\")\n",
    ")\n",
    "after_without_before = proj_phase.where(F.array_contains(\"phases\",\"After_RtB\") & ~F.array_contains(\"phases\",\"Before_RtB\"))\n",
    "if after_without_before.count() > 0:\n",
    "    issues.append(after_without_before.withColumn(\"issue\",\"PHASE_AFTER_WITHOUT_BEFORE\"))\n",
    "\n",
    "# 4.2 Un único Material Category por Project ID\n",
    "matcat = df_construction_cur.select(\"Project ID\",\"Material Category\").dropDuplicates()\n",
    "dup_matcat = (matcat.groupBy(\"Project ID\")\n",
    "              .agg(F.countDistinct(\"Material Category\").alias(\"n\"))\n",
    "              .where(\"n>1\"))\n",
    "if dup_matcat.count()>0:\n",
    "    issues.append(dup_matcat.withColumn(\"issue\",\"MULTIPLE_MATCAT_PER_PROJECT\"))\n",
    "\n",
    "# 4.3 Un único RtB Budget por Project ID (en registros After_RtB con presupuesto informado)\n",
    "budget = (df_construction_cur\n",
    "          .where((F.col(\"Project phase\")==\"After_RtB\") & F.col(\"RtB Budget\").isNotNull())\n",
    "          .select(\"Project ID\",\"RtB Budget\").dropDuplicates())\n",
    "dup_budget = (budget.groupBy(\"Project ID\")\n",
    "              .agg(F.countDistinct(\"RtB Budget\").alias(\"n\"))\n",
    "              .where(\"n>1\"))\n",
    "if dup_budget.count()>0:\n",
    "    issues.append(dup_budget.withColumn(\"issue\",\"MULTIPLE_RTB_BUDGET_PER_PROJECT\"))\n",
    "\n",
    "df_issues = None\n",
    "if issues:\n",
    "    df_issues = issues[0]\n",
    "    for extra in issues[1:]:\n",
    "        df_issues = df_issues.unionByName(extra, allowMissingColumns=True)\n",
    "else:\n",
    "    df_issues = spark.createDataFrame([], \"ProjectID string, n int, issue string\")\n",
    "\n",
    "df_issues.createOrReplaceTempView(\"vw_issues\")\n",
    "spark.sql(f\"CREATE DATABASE IF NOT EXISTS {DB_QA}\")\n",
    "spark.sql(f\"CREATE TABLE IF NOT EXISTS {OUT_QA} AS SELECT * FROM vw_issues WHERE 1=0\")\n",
    "# Insert (overwrite) hallazgos\n",
    "spark.sql(f\"TRUNCATE TABLE {OUT_QA}\")\n",
    "df_issues.write.mode(\"append\").saveAsTable(OUT_QA)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2429053",
   "metadata": {},
   "source": [
    "## 5) Guardar tablas curadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcd70c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "spark.sql(f\"CREATE DATABASE IF NOT EXISTS {DB_CUR}\")\n",
    "\n",
    "df_construction_cur.write.mode(\"overwrite\").saveAsTable(OUT_CONSTRUCTION)\n",
    "df_anybut_cur.write.mode(\"overwrite\").saveAsTable(OUT_ANYBUT)\n",
    "\n",
    "print(\"Curated tables written:\", OUT_CONSTRUCTION, OUT_ANYBUT)\n",
    "print(\"QA issues table:\", OUT_QA)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
